{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61c5dfa1-2b7d-452b-a4cf-c88cf60ad1d2",
   "metadata": {},
   "source": [
    "# Ray Architecture and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6efdfe-1158-4d89-8469-03cee2d0780c",
   "metadata": {},
   "source": [
    "[Ray Cluster](https://docs.ray.io/en/latest/cluster/key-concepts.html#id3)[](https://docs.ray.io/en/latest/cluster/key-concepts.html#ray-cluster \"Permalink to this headline\")\n",
    "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "A Ray cluster consists of a single [head node](https://docs.ray.io/en/latest/cluster/key-concepts.html#cluster-head-node) and any number of connected [worker nodes](https://docs.ray.io/en/latest/cluster/key-concepts.html#cluster-worker-nodes):\n",
    "\n",
    "[![../_images/ray-cluster.svg](https://docs.ray.io/en/latest/_images/ray-cluster.svg)](https://docs.ray.io/en/latest/_images/ray-cluster.svg)\n",
    "\n",
    "*A Ray cluster with two worker nodes. Each node runs Ray helper processes to facilitate distributed scheduling and memory management. The head node runs additional control processes (highlighted in blue).*[](https://docs.ray.io/en/latest/cluster/key-concepts.html#id1 \"Permalink to this image\")\n",
    "\n",
    "The number of worker nodes may be *autoscaled* with application demand as specified by your Ray cluster configuration. The head node runs the [autoscaler](https://docs.ray.io/en/latest/cluster/key-concepts.html#cluster-autoscaler).\n",
    "\n",
    "> Note: Ray nodes are implemented as pods when [running on Kubernetes](https://docs.ray.io/en/latest/cluster/kubernetes/index.html#kuberay-index).\n",
    "\n",
    "Users can submit jobs for execution on the Ray cluster, or can interactively use the cluster by connecting to the head node and running [`ray.init`](https://docs.ray.io/en/latest/ray-core/package-ref.html#ray.init \"ray.init\"). See [Ray Jobs](https://docs.ray.io/en/latest/cluster/running-applications/job-submission/quickstart.html#jobs-quickstart) for more information.\n",
    "\n",
    "[Head Node](https://docs.ray.io/en/latest/cluster/key-concepts.html#id4)[](https://docs.ray.io/en/latest/cluster/key-concepts.html#head-node \"Permalink to this headline\")\n",
    "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Every Ray cluster has one node which is designated as the *head node* of the cluster. The head node is identical to other worker nodes, except that it also runs singleton processes responsible for cluster management such as the [autoscaler](https://docs.ray.io/en/latest/cluster/key-concepts.html#cluster-autoscaler) and the Ray driver processes [which run Ray jobs](https://docs.ray.io/en/latest/cluster/key-concepts.html#cluster-clients-and-jobs). Ray may schedule tasks and actors on the head node just like any other worker node, unless configured otherwise.\n",
    "\n",
    "[Worker Node](https://docs.ray.io/en/latest/cluster/key-concepts.html#id5)[](https://docs.ray.io/en/latest/cluster/key-concepts.html#worker-node \"Permalink to this headline\")\n",
    "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "*Worker nodes* do not run any head node management processes, and serve only to run user code in Ray tasks and actors. They participate in distributed scheduling, as well as the storage and distribution of Ray objects in [cluster memory](https://docs.ray.io/en/latest/ray-core/scheduling/memory-management.html#memory).\n",
    "\n",
    "[Autoscaling](https://docs.ray.io/en/latest/cluster/key-concepts.html#id6)[](https://docs.ray.io/en/latest/cluster/key-concepts.html#autoscaling \"Permalink to this headline\")\n",
    "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "The *Ray autoscaler* is a process that runs on the [head node](https://docs.ray.io/en/latest/cluster/key-concepts.html#cluster-head-node) (or as a sidecar container in the head pod if [using Kubernetes](https://docs.ray.io/en/latest/cluster/kubernetes/index.html#kuberay-index)). When the resource demands of the Ray workload exceed the current capacity of the cluster, the autoscaler will try to increase the number of worker nodes. When worker nodes sit idle, the autoscaler will remove worker nodes from the cluster.\n",
    "\n",
    "It is important to understand that the autoscaler only reacts to task and actor resource requests, and not application metrics or physical resource utilization. To learn more about autoscaling, refer to the user guides for Ray clusters on [VMs](https://docs.ray.io/en/latest/cluster/vms/index.html#cloud-vm-index) and [Kubernetes](https://docs.ray.io/en/latest/cluster/kubernetes/index.html#kuberay-index).\n",
    "\n",
    "[Ray Jobs](https://docs.ray.io/en/latest/cluster/key-concepts.html#id7)[](https://docs.ray.io/en/latest/cluster/key-concepts.html#ray-jobs \"Permalink to this headline\")\n",
    "------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "A Ray job is a single application: it is the collection of Ray tasks, objects, and actors that originate from the same script. The worker that runs the Python script is known as the *driver* of the job.\n",
    "\n",
    "There are three ways to run a Ray job on a Ray cluster:\n",
    "\n",
    "1.  (Recommended) Submit the job using the [Ray Jobs API](https://docs.ray.io/en/latest/cluster/running-applications/job-submission/index.html#jobs-overview).\n",
    "\n",
    "2.  Run the driver script directly on any node of the Ray cluster, for interactive development.\n",
    "\n",
    "3.  Use [Ray Client](https://docs.ray.io/en/latest/cluster/running-applications/job-submission/ray-client.html#ray-client-ref) to connect remotely to the cluster within a driver script.\n",
    "\n",
    "For details on these workflows, refer to the [Ray Jobs API guide](https://docs.ray.io/en/latest/cluster/running-applications/job-submission/index.html#jobs-overview)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3f08d0-725a-4eec-8be0-0bb3686f950b",
   "metadata": {},
   "source": [
    "`pip install -U \"ray[air]\" # installs Ray + dependencies for Ray AI Runtime`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731f2d02-cf5e-4048-bed4-76e916cab276",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ray Dataset, Train, and Tune\n",
    "\n",
    "To illustrate Ray AIR's capabilities, you will implement an end-to-end example - predicting big tips with New York City Taxi data. Each section will introduce the Ray AIR library before demonstrating its functionality with code examples.\n",
    "\n",
    "|Ray AIR Component|Example Use Case|\n",
    "|:--|:--|\n",
    "|Ray Data|use `Preprocessor` to load and transform input data|\n",
    "|Ray Train|use `Trainer` to scale XGBoost model training|\n",
    "|Ray Tune|use `Tuner` for hyperparameter search|\n",
    "|Ray AIR Predictor|use `BatchPredictor` to load model from best checkpoint for batch inference|\n",
    "|Ray Serve|use `PredictorDeployment` for online inference|\n",
    "\n",
    "For this example, you will train [XGBoost](https://xgboost.readthedocs.io/en/stable/) model. XGBoost is a gradient boosted decision trees library, and you will set up a simple version for this classification task.\n",
    "\n",
    "You will use the June 2021 [New York City Taxi & Limousine Commission's Trip Record Data](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page) which contains over 2 million samples to predict whether a trip may result in a tip over 20%.\n",
    "\n",
    "**Key features**\n",
    "- `passenger_count`\n",
    "- `trip_distance` (in miles)\n",
    "- `fare_amount` (including tax, tip, fees, etc.)\n",
    "- `trip_duration` (in seconds)\n",
    "- `hour` (hour that the trip started)\n",
    "- `day_of_week`\n",
    "- `is_big_tip` (whether the tip amount was greater than 20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df24c2b-8a61-4d71-9055-65247fb2eb73",
   "metadata": {},
   "source": [
    "## Ray Data\n",
    "---\n",
    "\n",
    "First up, you will load in the taxi dataset and transform its raw input into features that will be given to our machine learning model.\n",
    "\n",
    "|<img src=\"images/data_highlight.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Ray AIR wraps Ray Data to provide distributed data ingestion and transformation during training, tuning, and inference.|\n",
    "\n",
    "### Introduction to Ray Datasets\n",
    "\n",
    "Backed by PyArrow, [Ray Datasets](https://docs.ray.io/en/latest/data/user-guide.html) parallelize loading and transforming data, and provide a standard way to pass references to data across Ray libraries and applications.\n",
    "\n",
    "#### Key features\n",
    "\n",
    "- **Flexibility**\n",
    "\n",
    "    Compatible with a variety of file formats, data sources, and distributed frameworks, Datasets work seamlessly with library integrations like Dask on Ray and can be passed between Ray tasks and actors without copying data.\n",
    "\n",
    "- **Performance for ML Workloads**\n",
    "\n",
    "    Datasets offers important features like accelerator support, pipelining, and global random shuffles that accelerate ML training and inference workloads along with basic distributed data transformations such as map, filter, sort, groupby, and repartition.\n",
    "\n",
    "- **Persistent Preprocessor**\n",
    "\n",
    "    The `Preprocessor` primitive explicitly captures and stores the transformations applied to convert inputs into features and is applied at both training and serving to keep the processing consistent across the pipeline.\n",
    "    \n",
    "- **Built on Ray Core**\n",
    "\n",
    "    Inherits scalability to hundreds of nodes, efficient memory usage due to memory across processes on the same node, and object spilling and recovery to handle failures. Because Datasets are just lists of object references, they can be passed between tasks and actors without needing to make a copy of the data, which is crucial for making data-intensive applications and libraries scalable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c1fbf9-2e5b-4ce9-be2b-38b4580c5956",
   "metadata": {},
   "source": [
    "### Start Ray runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9290c5be-d17a-4716-9c9b-1fa7d04aebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07efa93a-6f51-4e73-a66b-a52ce2901a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ray.is_initialized:\n",
    "    ray.shutdown()\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9becc86-bdf6-4f7c-be15-92e01eb2a429",
   "metadata": {},
   "source": [
    "Start a Ray cluster (check out these [instructions](https://docs.ray.io/en/latest/ray-overview/installation.html) if you haven't installed) so that Ray can utilize all the cores available to you as workers. \n",
    "\n",
    "- check `ray.is_initialized` to ensure that you start with a fresh cluster\n",
    "- use `ray.init()` to initialize a Ray context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd99c20c-b0ff-44a2-bc0f-11640e129be0",
   "metadata": {},
   "source": [
    "### Create Ray Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372a1cc3-e6b4-4a67-94c2-cfa5bd917319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read Parquet file to Ray Dataset\n",
    "dataset = ray.data.read_parquet(\n",
    "    \"s3://anyscale-training-data/intro-to-ray-air/nyc_taxi_2021.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5862ea-38b0-49f7-b2e4-c790da0d392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and validation subsets\n",
    "train_dataset, valid_dataset = dataset.train_test_split(test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705e54fe-6380-4d9e-9162-7c3d6c12bc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split datasets into blocks for parallel preprocessing\n",
    "# num_blocks should be lower than number of cores in the cluster\n",
    "train_dataset = train_dataset.repartition(num_blocks=5)\n",
    "valid_dataset = valid_dataset.repartition(num_blocks=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90bb2ac-ecc5-4637-9fff-69fb68868ec0",
   "metadata": {},
   "source": [
    "There exist many [`Dataset` API elements](https://docs.ray.io/en/latest/data/api/dataset.html#) available for common transformations and operations.\n",
    "\n",
    "We'll take a look at our data:\n",
    "\n",
    "1. Inspect the schema from the underlying Parquet metadata.\n",
    "2. Count how many rows are in the training and validation datasets.\n",
    "3. Inspect the first five samples of either dataset.\n",
    "4. What is the average `fare_amount` grouped by `passenger_count`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b460e216-ba96-48bc-a773-14eb8e5a532e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Schema of training dataset: \\n {train_dataset.schema()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c6a85-e042-49d7-9b5a-ad3e40717c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of samples in training dataset: \\n {train_dataset.count()}\")\n",
    "print(f\"Number of samples in validation dataset: \\n {valid_dataset.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dbf9c5-5c64-486e-9cce-d17de123a94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73605d18-dcaf-446f-a892-55f13bdb7743",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.groupby(\"passenger_count\").mean(\"fare_amount\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb5c307-ff06-4ce5-aed0-c67650c5057f",
   "metadata": {},
   "source": [
    "### Preprocess the dataset\n",
    "To transform our raw data into features, you will define a `Preprocessor`. Ray AIR's `Preprocessor` captures the data transformation you apply and persists:\n",
    "\n",
    "- **During Training**\n",
    "\n",
    "    `Preprocessor` is passed into a `Trainer` to `fit` and `transform` input `Dataset`s.\n",
    "- **During Tuning**\n",
    "\n",
    "    Each `Trial` will create its own copy of the `Preprocessor` and the fitting and transformation logic will occur once per `Trial`\n",
    "- **During Checkpointing**\n",
    "\n",
    "    The `Preprocessor` is saved in the `Checkpoint` if it was passed into the `Trainer`\n",
    "- **During Predicting**\n",
    "\n",
    "    If the `Checkpoint` contains a `Preprocessor`, then it will be used to call `transform_batch` on input batches prior to performing inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aecfb0b-8cbb-4525-b5de-9be28fef0205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.data.preprocessors import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e16ca1-ff83-498a-b171-f8fea14e9b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = MinMaxScaler(columns=[\"trip_distance\", \"trip_duration\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74443195-fe11-42c1-b539-a80b885e6cb3",
   "metadata": {},
   "source": [
    "You define a `MinMaxScaler` preprocessor that will normalize the `trip_distance` and `trip_duration` columns by their range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628c7d3d-f175-4645-8bad-90e03a062e0f",
   "metadata": {},
   "source": [
    "Ray AIR provides several [preprocessors out of the box](https://docs.ray.io/en/latest/ray-air/preprocessors.html#) as well as support for implementing custom preprocessors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737f99ed-6e05-4175-a84c-ae997acc5d37",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "#### Key concepts\n",
    "\n",
    "`Dataset`\n",
    "\n",
    "The standard way to load and exchange data in Ray AIR. In AIR, Datasets are used extensively for data loading, preprocessing, and batch inference.\n",
    "\n",
    "`Preprocessors`\n",
    "\n",
    "Preprocessors are primitives that can be used to transform input data into features. Preprocessors operate on Datasets, which makes them scalable and compatible with a variety of datasources and dataframe libraries.\n",
    "\n",
    "Preprocessors persist:\n",
    "\n",
    "- during training to fit and transform input data\n",
    "- in each trial of hyperparameter tuning\n",
    "- within a checkpoint\n",
    "- on input batches for inference\n",
    "\n",
    "AIR comes with a collection of built-in preprocessors, and you can also define your own with simple templates which you can read more about in the [user guide](https://docs.ray.io/en/latest/ray-air/preprocessors.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138eebf0-6435-4c1c-9293-ae1c88ca59bf",
   "metadata": {},
   "source": [
    "## Ray Train\n",
    "***\n",
    "\n",
    "Following data pre-processing, you can define the model for binary classification of big tip rides.\n",
    "\n",
    "|<img src=\"images/train_highlight.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Ray AIR wraps Ray Train to provide distributed model training.|\n",
    "\n",
    "### Introduction to Ray Train\n",
    "\n",
    "ML practitioners tend to run into a few common problems with training models that prompt them to consider distributed solutions:\n",
    "\n",
    "1. training time is too long to be practical\n",
    "2. the data is too large to fit on one machine\n",
    "3. training many models sequentially doesn't utilize resources efficiently\n",
    "4. the model itself is too large to fit on a single machine\n",
    "\n",
    "[Ray Train](https://docs.ray.io/en/latest/ray-air/trainer.html) addresses these issues by cutting down runtime through distributed multi-node training with fault tolerance and leveraging Ray Data to distribute preprocessing and data ingestion.\n",
    "\n",
    "Fully integrated into the Ray AIR ecosystem, `Trainer`s can plug into:\n",
    "\n",
    "- Ray Data: to enable scalable data loading and preprocessing\n",
    "- Ray Tune: for distributed hyperparameter tuning\n",
    "- Ray AIR Predictor: as a checkpointed trained model to be applied during inference\n",
    "- Popular ML training frameworks like:\n",
    "    - PyTorch\n",
    "    - Tensorflow\n",
    "    - Horovod\n",
    "    - XGBoost\n",
    "    - HuggingFace Transformers\n",
    "    - Scikit-Learn\n",
    "    - and more\n",
    "\n",
    "#### Key features\n",
    "\n",
    "* callbacks for early stopping\n",
    "* checkpointing\n",
    "* integration with Tensorboard, Weights & Biases, and MLflow for observability\n",
    "* export mechanisms for models\n",
    "\n",
    "|<img src=\"images/train_code.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Training comes in two major parts: defining the `Trainer` object and then fitting it to the training dataset. In this code snippet, you use a `TorchTrainer`, however, this may be swapped out with any [integrations](https://docs.ray.io/en/latest/ray-air/package-ref.html#trainer-and-predictor-integrations).|\n",
    "\n",
    "Let's put these concepts in practice by applying it to our taxi problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8564838-7886-4cad-9461-2af304dbb62e",
   "metadata": {},
   "source": [
    "### Define AIR `Trainer`\n",
    "\n",
    "Ray AIR provides a variety of [`Trainer`s](https://docs.ray.io/en/latest/ray-air/trainer.html) (PyTorch, Tensorflow, HuggingFace, etc.). In the example below, you will use an `XGBoostTrainer` to perform binary classification on these NYC Taxi rides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc861a5-4684-48dd-9927-dece7e85efd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.air.config import ScalingConfig\n",
    "from ray.train.xgboost import XGBoostTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceb3d15-61cb-4d8b-a39d-b46d9131201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = XGBoostTrainer(\n",
    "    label_column=\"is_big_tip\",\n",
    "    num_boost_round=50,\n",
    "    scaling_config=ScalingConfig(\n",
    "        num_workers=5,\n",
    "        use_gpu=False,\n",
    "    ),\n",
    "    params={\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": [\"logloss\", \"error\"],\n",
    "        \"tree_method\": \"approx\",\n",
    "    },\n",
    "    datasets={\"train\": train_dataset, \"valid\": valid_dataset},\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907621e8-66ca-4771-8102-19fc4011d353",
   "metadata": {},
   "source": [
    "To construct a `Trainer`, you provide:\n",
    "\n",
    "- a `ScalingConfig` which specifies how many parallel training workers and what type of resources (CPUs/GPUs) to use per worker during training\n",
    "- a dictionary of training and validation sets\n",
    "- the `Preprocessor` used to transform the `Dataset`s\n",
    "\n",
    "Optionally, you can choose to add `resume_from_checkpoint` which allows you to continue training from a saved checkpoint should the run be interrupted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccadd85-f1f8-4b9f-83f0-342988832f45",
   "metadata": {},
   "source": [
    "### Fit the Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a62af1-a7e8-4598-a3eb-e853b5491e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272ebbb1-3f5d-449c-84db-011a16991313",
   "metadata": {},
   "source": [
    "To invoke training, call `.fit()`. Trainer objects produce a `Result` object which gives you access to metrics, checkpoints, and errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb961db-55bd-4592-b4ca-2a1d3729f840",
   "metadata": {},
   "source": [
    "You can check out the training results from the `Result` object with the following calls:\n",
    "\n",
    "```python\n",
    "# returns last saved checkpoint\n",
    "result.checkpoint\n",
    "\n",
    "# returns the `n` best saved checkpoints as configured in `RunConfig.CheckpointConfig`\n",
    "result.best_checkpoints\n",
    "\n",
    "# returns the final metrics as reported\n",
    "result.metrics\n",
    "\n",
    "# returns the contain an Exception if training failed\n",
    "result.error\n",
    "```\n",
    "\n",
    "Inspect your training result below. What is the reported accuracy for the training and validation runs? \n",
    "\n",
    "Note: `error` is the binary classification error rate in this case calculated as `#(wrong cases)/#(all cases)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3025b9-3bb5-443d-bbe7-66da1390aaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Result metrics: \\n {result.metrics} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447443f0-b5f8-4e0c-8c95-a6b23c3f34a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training accuracy: {1 - result.metrics['train-error']:.4f}\")\n",
    "print(f\"Validation accuracy: {1 - result.metrics['valid-error']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3675961-c7d7-459b-859c-e401031f3df3",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "#### Key concepts\n",
    "\n",
    "`Trainer`\n",
    "\n",
    "Trainers are wrapper classes around third-party training frameworks such as XGBoost, Pytorch, and Tensorflow. They are built to help integrate with core Ray Actors (for distribution), Ray Datasets, and Ray Tune."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0134db1-c6a6-4a90-a9d6-4ab6567f1eb1",
   "metadata": {},
   "source": [
    "## Ray Tune\n",
    "***\n",
    "\n",
    "Now that you have a baseline XGBoost model trained, you may want to improve performance by running hyperparameter tuning experiments.\n",
    "\n",
    "|<img src=\"images/tune_highlight.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|Ray AIR wraps Ray Tune to provide distributed hyperparameter optimization.|\n",
    "\n",
    "### Introduction to Ray Tune\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <strong><a href=\"https://en.wikipedia.org/wiki/Hyperparameter_optimization\" target=\"_blank\">Hyperparameter tuning (or optimization) (HPO)</a></strong> is the process of choosing optimal hyperparameters for a machine learning model. Hyperparameters, in contrast to weights learned by the model, are parameters that you set to influence training.\n",
    "</div>\n",
    "\n",
    "\n",
    "Setting up and executing hyperparameter optimization (HPO) can be expensive in terms of compute resources and runtime with several complexities including:\n",
    "\n",
    "- **Vast Search Space**\n",
    "\n",
    "    Your model could have several hyperparameters, each with different data types, ranges, and possible correlations.\n",
    "    Sampling good candidates from high-dimensional spaces is difficult.\n",
    "- **Search Algorithms**\n",
    "\n",
    "    Choosing hyperparameters strategically requires testing complex search algorithms to achieve good results.\n",
    "- **Long Runtime**\n",
    "\n",
    "    Even if you distribute tuning, training complex models in themselves can take a long time to complete per run, so it's best to have an efficiency at every stage in the pipeline.\n",
    "- **Resource Allocation**\n",
    "\n",
    "    You must have enough compute resources available to during each trial as to not slow down search because of scheduling mismatches.\n",
    "- **User Experience**\n",
    "\n",
    "    Observability tooling for developers like stopping bad runs early, saving intermediate results, restarting from checkpoints, or pausing/resuming runs makes HPO easier.\n",
    "\n",
    "Ray Tune is a distributed HPO library that addresses all of these topics above to provide a simplified interface for running trials and integrates with popular frameworks such as HyperOpt and Optuna.\n",
    "\n",
    "|<img src=\"images/tune_code.png\" width=\"70%\" loading=\"lazy\">|\n",
    "|:--|\n",
    "|General pattern for using AIR `Tuner`s which involves taking in a trainable, defining a search space, establishing a search algorithm, scheduling trials, and analyzing results.|\n",
    "\n",
    "Let's see how to interact with Ray Tune to make some improvements to our big tip classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be90767-080c-4bd3-97fb-13989d7e938c",
   "metadata": {},
   "source": [
    "### Use AIR `Tuner` for hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf8378f-a971-418e-a8d1-8c63fdf7f395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.tune.tuner import Tuner, TuneConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec3d582-a911-47c8-b0ec-753b4c0ca619",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    \"params\": {\n",
    "        \"eta\": tune.uniform(0.2, 0.4),\n",
    "        \"max_depth\": tune.randint(1, 6),\n",
    "        \"min_child_weight\": tune.uniform(0.8, 1.0),\n",
    "    }\n",
    "}\n",
    "\n",
    "tuner = Tuner(\n",
    "    trainer,\n",
    "    param_space=param_space,\n",
    "    tune_config=TuneConfig(num_samples=3, metric=\"train-logloss\", mode=\"min\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c9dbf4-b12b-42fc-a005-f8cad9b140e5",
   "metadata": {},
   "source": [
    "First define a search space with a few hyperparameters to tune:\n",
    "\n",
    "- `eta` is the learning rate\n",
    "- `max_depth` specifies how deep each tree is (default=6). A higher value leads to a more complex model.\n",
    "- `min_child_weight` defines the minimum sum of weights of all observations in a child; used to control overfitting\n",
    "\n",
    "To set up an AIR `Tuner`, you must specify:\n",
    "\n",
    "- `Trainer`: the training loop\n",
    "- `search space`: a set of hyperparameters you wish to tune\n",
    "- `search_algorithm`: to optimize parameter search\n",
    "- `scheduler`: (optional) to stop searches early and speed up experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6b9787-d727-40a1-bfac-5522450205bc",
   "metadata": {},
   "source": [
    "### Execute hyperparameter search and analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b72594a-3478-4297-8950-1854e902903f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_grid = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8502ff-1ba7-42ae-a28b-49f421abf736",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = result_grid.get_best_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e984aeaa-e2fd-4eaa-8244-663cb94581f8",
   "metadata": {},
   "source": [
    "Now, you can execute tuning on `num_samples=10` trials. After tuning, you can query the `ResultGrid` object to see metrics, results, and checkpoints of each trial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8192447-8e65-4299-8e23-010c7ff950ca",
   "metadata": {},
   "source": [
    "You can probe the `ResultGrid` for metrics using these calls:\n",
    "\n",
    "```python\n",
    "\n",
    "# checks if there have been errors\n",
    "result_grid.errors\n",
    "\n",
    "# gets the best result\n",
    "best_result = result_grid.get_best_result()\n",
    "\n",
    "# gets the best checkpoint\n",
    "best_checkpoint = best_result.checkpoint\n",
    "\n",
    "# gets the best metrics\n",
    "best_metrics = best_result.metrics\n",
    "\n",
    "```\n",
    "\n",
    "Inspect your tuning results, what is the best result from these experiments? Are they better than the baseline model in the training step in the previous section?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e39bfa-e6d4-45f2-a3a3-8cb4c8197f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = result_grid.get_best_result()\n",
    "print(f\"Best result: \\n {best_result} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a915e808-941f-4251-903a-8fb996cdff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training accuracy: {1 - best_result.metrics['train-error']:.4f}\")\n",
    "print(f\"Validation accuracy: {1 - best_result.metrics['valid-error']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e38981c-ac72-4d5f-bc48-519e8761eef1",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "#### Key concepts\n",
    "\n",
    "`Tuner`\n",
    "\n",
    "Provides an interface that works with AIR `Trainer`s to perform distributed hyperparameter tuning. You define a set of hyperparameters you wish to tune in a search space, specify a search algorithm, and the `Tuner` returns its results in a `ResultGrid` that contains metrics, results, and checkpoints for each `trial`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
